:: Start ::
[LOG] CFG ENKO  {'DEBUG': False, 'train_batch_size': 64, 'valid_batch_size': 128, 'num_epochs': 20, 'num_checkpoints': 3, 'max_token_length': 512, 'stopwords': [], 'learning_rate': 0.0005, 'weight_decay': 0.01, 'adam_beta_1': 0.9, 'adam_beta_2': 0.98, 'epsilon': 1e-09, 'fp16': False, 'gradient_accumulation_steps': 2, 'save_steps': 150, 'logging_steps': 150, 'evaluation_strategy': 'epoch', 'inference_model_name': 'QuoQA-NLP/KE-T5-Ko2En-Base', 'no_inference_sentences': 100, 'num_beams': 5, 'repetition_penalty': 1.3, 'no_repeat_ngram_size': 3, 'num_return_sequences': 1, 'src_language': 'ko', 'tgt_language': 'en', 'model_name': 'QuoQA-NLP/KE-T5-Ko2En-Base', 'num_inference_sample': 120, 'dropout': 0.1, 'ROOT_PATH': '.', 'save_path': './results_Ko2En'}
LOG model_name QuoQA-NLP/KE-T5-Ko2En-Base
LOG inference is done.
  0%|          | 0/277 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [00:00<00:00, 29887.64it/s]
/home/013907062/OpenNMT-tf/scripts/HuggingFace/QuoQA-NLP/Final/testscript.py:53: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric("sacrebleu")
Using the latest cached version of the module from /home/013907062/.cache/huggingface/modules/datasets_modules/metrics/sacrebleu/556ba16a9634185dd1ea68395e0e474d6ee4de7e123fa701d577c6461f06032b (last modified on Thu Sep 14 16:32:47 2023) since it couldn't be found locally at sacrebleu, or remotely on the Hugging Face Hub.
LOG results file saved.
LOG metric done
{'score': 35.5471391149334, 'counts': [2421, 1461, 957, 627], 'totals': [3792, 3515, 3238, 2962], 'precisions': [63.84493670886076, 41.5647226173542, 29.555281037677577, 21.168129642133692], 'bp': 0.9902900648538328, 'sys_len': 3792, 'ref_len': 3829}
