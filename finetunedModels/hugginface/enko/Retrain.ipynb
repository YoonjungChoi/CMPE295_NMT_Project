{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8365b548-4d7b-4415-bd10-09bd7c32dbda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "VAdepthENV               /home/013907062/.conda/envs/VAdepthENV\n",
      "env_onmttf               /home/013907062/.conda/envs/env_onmttf\n",
      "koen_base                /home/013907062/.conda/envs/koen_base\n",
      "newDepth                 /home/013907062/.conda/envs/newDepth\n",
      "test                     /home/013907062/.conda/envs/test\n",
      "wmt_infer             *  /home/013907062/.conda/envs/wmt_infer\n",
      "base                     /opt/ohpc/pub/apps/anaconda/3.9\n",
      "stylegan2                /opt/ohpc/pub/apps/anaconda/3.9/envs/stylegan2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1d7fbcf-2cb3-466a-a483-44ab98d90c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: huggingface-hub\n",
      "Version: 0.17.1\n",
      "Summary: Client library to download and publish models, datasets and other repos on the huggingface.co hub\n",
      "Home-page: https://github.com/huggingface/huggingface_hub\n",
      "Author: Hugging Face, Inc.\n",
      "Author-email: julien@huggingface.co\n",
      "License: Apache\n",
      "Location: /home/013907062/.conda/envs/wmt_infer/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, packaging, pyyaml, requests, tqdm, typing-extensions\n",
      "Required-by: accelerate, autonlp, datasets, transformers\n"
     ]
    }
   ],
   "source": [
    "!pip show huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3430f8-2585-45b2-947d-f1762966b8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install sacrebleu\n",
    "!pip install sentencepiece\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071bba9-aae8-4092-91d4-954324f9cf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers -U\n",
    "!pip install huggingface_hub -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fb6b2-2655-4f04-894a-03a45671e731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b4eb7c-a91f-41e5-bafb-59a2ba2043e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from easydict import EasyDict\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85191a1-fcea-4e0d-bf9a-4f61891b8936",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/013907062/.conda/envs/wmt_infer/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7efcbe5-f0cb-4dc8-a368-2a6e166d118c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3709fd9b-2dc3-426d-a03c-21df742ec203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b75dde5-f1af-42e6-8fbf-b338c608a740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158539/1705689326.py:6: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG YJ] QuoQA-NLP/KE-T5-En2Ko-Base\n",
      "[LOG YJ] DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['en', 'ko'],\n",
      "        num_rows: 1830\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['en', 'ko'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Read config.yaml file\n",
    "with open(\"config.yaml\") as infile:\n",
    "    SAVED_CFG = yaml.load(infile, Loader=yaml.FullLoader)\n",
    "    CFG = EasyDict(SAVED_CFG[\"CFG\"])\n",
    "\n",
    "metric = load_metric(\"sacrebleu\")\n",
    "\n",
    "# all dataset\n",
    "#dset = load_dataset(CFG.dset_name, use_auth_token=True)\n",
    "dset = load_dataset(\"csv\", data_files={'train':'idioms_train.csv','valid': 'idioms__eval.csv'})\n",
    "print(\"[LOG YJ]\", CFG.model_name)\n",
    "#QuoQA-NLP/KE-T5-En2Ko-Base\n",
    "#tokenizer = T5Tokenizer.from_pretrained(CFG.model_name)  # https://github.com/AIRC-KETI/ke-t5#models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"QuoQA-NLP/KE-T5-En2Ko-Base\")\n",
    "print(\"[LOG YJ]\", dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b69ab2f-1f84-4311-b611-521d0330171f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG YJ] CPU_COUNT  14\n",
      "[LOG YJ] tokenized_datasets done\n",
      "[LOG YJ] run_name KE-T5-En2Ko-Base-finetuned-en-to-ko\n",
      "[LOG YJ] Trainer Ready DONE!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples[CFG.src_language]\n",
    "    targets = examples[CFG.tgt_language]\n",
    "    model_inputs = tokenizer(inputs, max_length=CFG.max_token_length, truncation=True)\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=CFG.max_token_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# print(preprocess_function(dset[\"train\"].select(range(0, 2))))\n",
    "\n",
    "CPU_COUNT = multiprocessing.cpu_count() // 2\n",
    "print(\"[LOG YJ] CPU_COUNT \", CPU_COUNT)\n",
    "\n",
    "tokenized_datasets = dset.map(preprocess_function, batched=True, num_proc=CPU_COUNT)\n",
    "print(\"[LOG YJ] tokenized_datasets done\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(CFG.model_name)\n",
    "\n",
    "str_model_name = CFG.model_name.split(\"/\")[-1]\n",
    "run_name = f\"{str_model_name}-finetuned-{CFG.src_language}-to-{CFG.tgt_language}\"\n",
    "\n",
    "print(\"[LOG YJ] run_name\", run_name)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    run_name,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    per_device_train_batch_size=CFG.train_batch_size,\n",
    "    per_device_eval_batch_size=CFG.valid_batch_size,\n",
    "    evaluation_strategy=CFG.evaluation_strategy,\n",
    "    # eval_steps=CFG.eval_steps,\n",
    "    save_steps=CFG.save_steps,\n",
    "    num_train_epochs=CFG.num_epochs,\n",
    "    save_total_limit=CFG.num_checkpoints,\n",
    "    predict_with_generate=True,\n",
    "    fp16=CFG.fp16,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    logging_steps=CFG.logging_steps,\n",
    ")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(\"[LOG YJ] Trainer Ready DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e98101b-b81f-4b14-9774-e699d30ec0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "trainer.save_model(CFG.save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
