CFG:
  DEBUG: false
  train_batch_size: 64
  valid_batch_size: 128

  # Train configuration
  num_epochs:  10  # validation loss is increasing after 5 epochs
  num_checkpoints: 3
  max_token_length: 512
  stopwords: []
  learning_rate: 0.0005 # has to be set as float explicitly due to https://stackoverflow.com/questions/30458977/yaml-loads-5e-6-as-string-and-not-a-number
  weight_decay: 0.01 # https://paperswithcode.com/method/weight-decay
  adam_beta_1: 0.9
  adam_beta_2: 0.98
  epsilon: 0.000000001
  fp16: false
  gradient_accumulation_steps: 2
  save_steps: 150
  logging_steps: 150
  evaluation_strategy: "epoch"

  # Evaluation configuration
  inference_model_name: "QuoQA-NLP/KE-T5-Ko2En-Base"
  no_inference_sentences: 100
  num_beams: 5
  repetition_penalty: 1.3
  no_repeat_ngram_size: 3
  num_return_sequences: 1

  # Translation settings
  #dset_name: "LeverageX/AIHUB-all-parallel-ko-en" # or LeverageX/AIHUB-socio-parallel-ko-en
  src_language: "ko"
  tgt_language: "en"
  model_name: "QuoQA-NLP/KE-T5-Ko2En-Base"
  num_inference_sample: 120
  dropout: 0.1

  # root path
  ROOT_PATH: "."
  save_path: "./results_Ko2En"
